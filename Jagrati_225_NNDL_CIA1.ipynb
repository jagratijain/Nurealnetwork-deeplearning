{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h-PJkgsBEHLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1:**\n",
        "\n",
        "# Part II: XOR Gate Implementation"
      ],
      "metadata": {
        "id": "4mq_2F026FY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the following:\n",
        "Scenario:\n",
        "The XOR gate is known for its complexity, as it outputs 1 only when the inputs are different.\n",
        "This is a challenge for a Single Layer Perceptron since XOR is not linearly separable.\n",
        "• Lab Task: Attempt to implement a Single Layer Perceptron in Google Colab to classify the\n",
        "output of an XOR gate. Perform the following steps:"
      ],
      "metadata": {
        "id": "G1IuQR2cIoU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. XOR Truth Table Dataset:**"
      ],
      "metadata": {
        "id": "fsuF6MIj6Oyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OlfEYLb6ywpw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# XOR gate truth table\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs\n",
        "y = np.array([0, 1, 1, 0])  # XOR output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Single-Layer Perceptron Implementation:**"
      ],
      "metadata": {
        "id": "0ppAgl7i6Syt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create a simple perceptron model\n",
        "single_layer_model = Sequential()\n",
        "single_layer_model.add(Dense(1, input_dim=2, activation='hard_sigmoid'))  # Single layer\n",
        "\n",
        "# Compile the model\n",
        "single_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the perceptron on the XOR data\n",
        "single_layer_model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Evaluate the performance\n",
        "loss, accuracy = single_layer_model.evaluate(X, y)\n",
        "print(f'Single Layer Perceptron Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBy0eca_6Tjk",
        "outputId": "46773fb3-112d-46f1-ad4f-5a381053796e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6956\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6941\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5000 - loss: 0.6941\n",
            "Single Layer Perceptron Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Single-Layer Perceptron:**\n",
        "\n",
        "The model will struggle to converge because XOR is not linearly separable, and the perceptron will not achieve a high accuracy."
      ],
      "metadata": {
        "id": "_SPz6fQh6afA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h4>After running the above code, you'll notice that the Single Layer Perceptron fails to correctly classify the XOR gate because it can only form linear decision boundaries. The perceptron's output will likely be incorrect for some input combinations.</h4>\n",
        "\n",
        "<h4>Observations:</h4>\n",
        "<h4>The perceptron will struggle to separate the data because the XOR problem is non-linearly separable.</h4>\n",
        "<h4>This highlights the limitations of a Single Layer Perceptron, particularly with a linear activation function like the MCP Neuron.</h4>"
      ],
      "metadata": {
        "id": "7EGpM0cDIslj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Multi-Layer Perceptron (MLP) Implementation:**"
      ],
      "metadata": {
        "id": "AmS0zSVf6jNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Multi-Layer Perceptron can solve the XOR problem as it introduces a hidden layer that can handle non-linear decision boundaries. We will use the MLPClassifier from scikit-learn with at least one hidden layer."
      ],
      "metadata": {
        "id": "Zd3RGpGcIwGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Multi-Layer Perceptron model with a hidden layer\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Dense(2, input_dim=2, activation='relu'))  # Hidden layer with 2 neurons\n",
        "mlp_model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "mlp_model.fit(X, y, epochs=500, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = mlp_model.evaluate(X, y)\n",
        "print(f'Multi-Layer Perceptron Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbnNv_qw6c6X",
        "outputId": "a5ca0e2e-2c52-4f36-bb62-8d2db1a3f8ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6960\n",
            "Epoch 2/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6956\n",
            "Epoch 3/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 4/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 5/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 6/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 7/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 8/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6930\n",
            "Epoch 9/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6926\n",
            "Epoch 10/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6922\n",
            "Epoch 11/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6918\n",
            "Epoch 12/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6914\n",
            "Epoch 13/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6910\n",
            "Epoch 14/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6907\n",
            "Epoch 15/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6903\n",
            "Epoch 16/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6899\n",
            "Epoch 17/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6895\n",
            "Epoch 18/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6891\n",
            "Epoch 19/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6887\n",
            "Epoch 20/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6884\n",
            "Epoch 21/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6880\n",
            "Epoch 22/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6876\n",
            "Epoch 23/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6873\n",
            "Epoch 24/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6869\n",
            "Epoch 25/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6866\n",
            "Epoch 26/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6862\n",
            "Epoch 27/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6859\n",
            "Epoch 28/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6855\n",
            "Epoch 29/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6852\n",
            "Epoch 30/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6848\n",
            "Epoch 31/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6845\n",
            "Epoch 32/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6842\n",
            "Epoch 33/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6838\n",
            "Epoch 34/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6835\n",
            "Epoch 35/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6832\n",
            "Epoch 36/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6829\n",
            "Epoch 37/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6826\n",
            "Epoch 38/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6822\n",
            "Epoch 39/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6819\n",
            "Epoch 40/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6816\n",
            "Epoch 41/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6813\n",
            "Epoch 42/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6810\n",
            "Epoch 43/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6807\n",
            "Epoch 44/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6804\n",
            "Epoch 45/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6801\n",
            "Epoch 46/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6798\n",
            "Epoch 47/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6795\n",
            "Epoch 48/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6793\n",
            "Epoch 49/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6790\n",
            "Epoch 50/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6787\n",
            "Epoch 51/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6784\n",
            "Epoch 52/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6781\n",
            "Epoch 53/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6779\n",
            "Epoch 54/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6776\n",
            "Epoch 55/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6773\n",
            "Epoch 56/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6770\n",
            "Epoch 57/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6768\n",
            "Epoch 58/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6765\n",
            "Epoch 59/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6762\n",
            "Epoch 60/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6760\n",
            "Epoch 61/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6757\n",
            "Epoch 62/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6755\n",
            "Epoch 63/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6752\n",
            "Epoch 64/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6750\n",
            "Epoch 65/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6747\n",
            "Epoch 66/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6744\n",
            "Epoch 67/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5000 - loss: 0.6742\n",
            "Epoch 68/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6739\n",
            "Epoch 69/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.6737\n",
            "Epoch 70/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5000 - loss: 0.6735\n",
            "Epoch 71/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.6732\n",
            "Epoch 72/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6730\n",
            "Epoch 73/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6727\n",
            "Epoch 74/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6725\n",
            "Epoch 75/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6722\n",
            "Epoch 76/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6720\n",
            "Epoch 77/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6718\n",
            "Epoch 78/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6715\n",
            "Epoch 79/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6713\n",
            "Epoch 80/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6711\n",
            "Epoch 81/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6708\n",
            "Epoch 82/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6706\n",
            "Epoch 83/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6704\n",
            "Epoch 84/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6701\n",
            "Epoch 85/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6699\n",
            "Epoch 86/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6697\n",
            "Epoch 87/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6694\n",
            "Epoch 88/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6692\n",
            "Epoch 89/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6690\n",
            "Epoch 90/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6687\n",
            "Epoch 91/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6685\n",
            "Epoch 92/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6683\n",
            "Epoch 93/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6681\n",
            "Epoch 94/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6678\n",
            "Epoch 95/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6676\n",
            "Epoch 96/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6674\n",
            "Epoch 97/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6671\n",
            "Epoch 98/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6669\n",
            "Epoch 99/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6667\n",
            "Epoch 100/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.6665\n",
            "Epoch 101/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.6662\n",
            "Epoch 102/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5000 - loss: 0.6660\n",
            "Epoch 103/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6658\n",
            "Epoch 104/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6656\n",
            "Epoch 105/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6653\n",
            "Epoch 106/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6651\n",
            "Epoch 107/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6649\n",
            "Epoch 108/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6647\n",
            "Epoch 109/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6645\n",
            "Epoch 110/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6642\n",
            "Epoch 111/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6640\n",
            "Epoch 112/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5000 - loss: 0.6638\n",
            "Epoch 113/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5000 - loss: 0.6636\n",
            "Epoch 114/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6633\n",
            "Epoch 115/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.6631\n",
            "Epoch 116/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5000 - loss: 0.6629\n",
            "Epoch 117/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6627\n",
            "Epoch 118/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5000 - loss: 0.6624\n",
            "Epoch 119/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6622\n",
            "Epoch 120/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6620\n",
            "Epoch 121/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.6618\n",
            "Epoch 122/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6616\n",
            "Epoch 123/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6613\n",
            "Epoch 124/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6611\n",
            "Epoch 125/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6609\n",
            "Epoch 126/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6607\n",
            "Epoch 127/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.6605\n",
            "Epoch 128/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6602\n",
            "Epoch 129/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5000 - loss: 0.6600\n",
            "Epoch 130/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6598\n",
            "Epoch 131/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.6596\n",
            "Epoch 132/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6593\n",
            "Epoch 133/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.6591\n",
            "Epoch 134/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5000 - loss: 0.6589\n",
            "Epoch 135/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.6587\n",
            "Epoch 136/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6585\n",
            "Epoch 137/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6582\n",
            "Epoch 138/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6580\n",
            "Epoch 139/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6578\n",
            "Epoch 140/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6576\n",
            "Epoch 141/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6574\n",
            "Epoch 142/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6571\n",
            "Epoch 143/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6569\n",
            "Epoch 144/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6567\n",
            "Epoch 145/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6565\n",
            "Epoch 146/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6563\n",
            "Epoch 147/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6560\n",
            "Epoch 148/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6558\n",
            "Epoch 149/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6556\n",
            "Epoch 150/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6554\n",
            "Epoch 151/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6552\n",
            "Epoch 152/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6550\n",
            "Epoch 153/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6547\n",
            "Epoch 154/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6545\n",
            "Epoch 155/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6543\n",
            "Epoch 156/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6541\n",
            "Epoch 157/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6539\n",
            "Epoch 158/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6536\n",
            "Epoch 159/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6534\n",
            "Epoch 160/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6532\n",
            "Epoch 161/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6530\n",
            "Epoch 162/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.6528\n",
            "Epoch 163/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6525\n",
            "Epoch 164/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6523\n",
            "Epoch 165/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6521\n",
            "Epoch 166/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6519\n",
            "Epoch 167/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6517\n",
            "Epoch 168/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6515\n",
            "Epoch 169/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6512\n",
            "Epoch 170/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6510\n",
            "Epoch 171/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6508\n",
            "Epoch 172/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.6506\n",
            "Epoch 173/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6504\n",
            "Epoch 174/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6502\n",
            "Epoch 175/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6499\n",
            "Epoch 176/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6497\n",
            "Epoch 177/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6495\n",
            "Epoch 178/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6493\n",
            "Epoch 179/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6491\n",
            "Epoch 180/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6489\n",
            "Epoch 181/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6486\n",
            "Epoch 182/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6484\n",
            "Epoch 183/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6482\n",
            "Epoch 184/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6480\n",
            "Epoch 185/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6478\n",
            "Epoch 186/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6476\n",
            "Epoch 187/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6473\n",
            "Epoch 188/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6471\n",
            "Epoch 189/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6469\n",
            "Epoch 190/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6467\n",
            "Epoch 191/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6465\n",
            "Epoch 192/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6463\n",
            "Epoch 193/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6460\n",
            "Epoch 194/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6458\n",
            "Epoch 195/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6456\n",
            "Epoch 196/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6454\n",
            "Epoch 197/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6452\n",
            "Epoch 198/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6450\n",
            "Epoch 199/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6448\n",
            "Epoch 200/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6445\n",
            "Epoch 201/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6443\n",
            "Epoch 202/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6441\n",
            "Epoch 203/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6439\n",
            "Epoch 204/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6437\n",
            "Epoch 205/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6435\n",
            "Epoch 206/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6433\n",
            "Epoch 207/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6430\n",
            "Epoch 208/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6428\n",
            "Epoch 209/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6426\n",
            "Epoch 210/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6424\n",
            "Epoch 211/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6422\n",
            "Epoch 212/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6420\n",
            "Epoch 213/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6417\n",
            "Epoch 214/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6415\n",
            "Epoch 215/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6413\n",
            "Epoch 216/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6411\n",
            "Epoch 217/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6409\n",
            "Epoch 218/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6408\n",
            "Epoch 219/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6408\n",
            "Epoch 220/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6407\n",
            "Epoch 221/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6405\n",
            "Epoch 222/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6403\n",
            "Epoch 223/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6400\n",
            "Epoch 224/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6398\n",
            "Epoch 225/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6397\n",
            "Epoch 226/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6396\n",
            "Epoch 227/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6394\n",
            "Epoch 228/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6393\n",
            "Epoch 229/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6391\n",
            "Epoch 230/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6390\n",
            "Epoch 231/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6388\n",
            "Epoch 232/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6387\n",
            "Epoch 233/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6385\n",
            "Epoch 234/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6383\n",
            "Epoch 235/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6381\n",
            "Epoch 236/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7500 - loss: 0.6379\n",
            "Epoch 237/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6377\n",
            "Epoch 238/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6377\n",
            "Epoch 239/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6376\n",
            "Epoch 240/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6374\n",
            "Epoch 241/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6372\n",
            "Epoch 242/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6370\n",
            "Epoch 243/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6368\n",
            "Epoch 244/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6367\n",
            "Epoch 245/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6366\n",
            "Epoch 246/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6364\n",
            "Epoch 247/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6362\n",
            "Epoch 248/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6361\n",
            "Epoch 249/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6359\n",
            "Epoch 250/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6357\n",
            "Epoch 251/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6355\n",
            "Epoch 252/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6354\n",
            "Epoch 253/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6353\n",
            "Epoch 254/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6351\n",
            "Epoch 255/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6349\n",
            "Epoch 256/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6348\n",
            "Epoch 257/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6346\n",
            "Epoch 258/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6345\n",
            "Epoch 259/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6343\n",
            "Epoch 260/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6341\n",
            "Epoch 261/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6340\n",
            "Epoch 262/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6338\n",
            "Epoch 263/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6336\n",
            "Epoch 264/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6335\n",
            "Epoch 265/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6333\n",
            "Epoch 266/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6332\n",
            "Epoch 267/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6330\n",
            "Epoch 268/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6329\n",
            "Epoch 269/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6327\n",
            "Epoch 270/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6325\n",
            "Epoch 271/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6324\n",
            "Epoch 272/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6322\n",
            "Epoch 273/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6321\n",
            "Epoch 274/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6319\n",
            "Epoch 275/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6318\n",
            "Epoch 276/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6316\n",
            "Epoch 277/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6314\n",
            "Epoch 278/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6313\n",
            "Epoch 279/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6311\n",
            "Epoch 280/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6309\n",
            "Epoch 281/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6308\n",
            "Epoch 282/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6307\n",
            "Epoch 283/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6305\n",
            "Epoch 284/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6303\n",
            "Epoch 285/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6302\n",
            "Epoch 286/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6300\n",
            "Epoch 287/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6299\n",
            "Epoch 288/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.6298\n",
            "Epoch 289/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6296\n",
            "Epoch 290/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6294\n",
            "Epoch 291/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6292\n",
            "Epoch 292/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6290\n",
            "Epoch 293/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6289\n",
            "Epoch 294/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7500 - loss: 0.6288\n",
            "Epoch 295/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.7500 - loss: 0.6286\n",
            "Epoch 296/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.7500 - loss: 0.6284\n",
            "Epoch 297/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6283\n",
            "Epoch 298/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6281\n",
            "Epoch 299/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6279\n",
            "Epoch 300/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6278\n",
            "Epoch 301/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6276\n",
            "Epoch 302/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6274\n",
            "Epoch 303/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7500 - loss: 0.6273\n",
            "Epoch 304/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7500 - loss: 0.6271\n",
            "Epoch 305/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.7500 - loss: 0.6270\n",
            "Epoch 306/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.6268\n",
            "Epoch 307/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6267\n",
            "Epoch 308/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6265\n",
            "Epoch 309/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7500 - loss: 0.6263\n",
            "Epoch 310/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6262\n",
            "Epoch 311/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7500 - loss: 0.6260\n",
            "Epoch 312/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7500 - loss: 0.6259\n",
            "Epoch 313/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7500 - loss: 0.6257\n",
            "Epoch 314/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - accuracy: 0.7500 - loss: 0.6255\n",
            "Epoch 315/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7500 - loss: 0.6254\n",
            "Epoch 316/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6252\n",
            "Epoch 317/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6250\n",
            "Epoch 318/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6249\n",
            "Epoch 319/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6247\n",
            "Epoch 320/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6246\n",
            "Epoch 321/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6244\n",
            "Epoch 322/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6243\n",
            "Epoch 323/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.6241\n",
            "Epoch 324/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 0.6239\n",
            "Epoch 325/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6238\n",
            "Epoch 326/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6236\n",
            "Epoch 327/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6235\n",
            "Epoch 328/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6233\n",
            "Epoch 329/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6231\n",
            "Epoch 330/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6230\n",
            "Epoch 331/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6228\n",
            "Epoch 332/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6226\n",
            "Epoch 333/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6225\n",
            "Epoch 334/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 0.6223\n",
            "Epoch 335/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7500 - loss: 0.6222\n",
            "Epoch 336/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.6220\n",
            "Epoch 337/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7500 - loss: 0.6219\n",
            "Epoch 338/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7500 - loss: 0.6217\n",
            "Epoch 339/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6215\n",
            "Epoch 340/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6214\n",
            "Epoch 341/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6212\n",
            "Epoch 342/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6211\n",
            "Epoch 343/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6209\n",
            "Epoch 344/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6207\n",
            "Epoch 345/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7500 - loss: 0.6206\n",
            "Epoch 346/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6204\n",
            "Epoch 347/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6203\n",
            "Epoch 348/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6201\n",
            "Epoch 349/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6200\n",
            "Epoch 350/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7500 - loss: 0.6198\n",
            "Epoch 351/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 0.6196\n",
            "Epoch 352/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6194\n",
            "Epoch 353/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6193\n",
            "Epoch 354/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6191\n",
            "Epoch 355/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6190\n",
            "Epoch 356/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6188\n",
            "Epoch 357/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6187\n",
            "Epoch 358/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6185\n",
            "Epoch 359/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6183\n",
            "Epoch 360/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6181\n",
            "Epoch 361/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6180\n",
            "Epoch 362/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6178\n",
            "Epoch 363/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6177\n",
            "Epoch 364/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6175\n",
            "Epoch 365/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6174\n",
            "Epoch 366/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6172\n",
            "Epoch 367/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6171\n",
            "Epoch 368/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6169\n",
            "Epoch 369/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6167\n",
            "Epoch 370/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6166\n",
            "Epoch 371/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6164\n",
            "Epoch 372/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6163\n",
            "Epoch 373/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6160\n",
            "Epoch 374/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6159\n",
            "Epoch 375/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6157\n",
            "Epoch 376/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6156\n",
            "Epoch 377/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6154\n",
            "Epoch 378/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6153\n",
            "Epoch 379/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6151\n",
            "Epoch 380/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6149\n",
            "Epoch 381/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6148\n",
            "Epoch 382/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6146\n",
            "Epoch 383/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6144\n",
            "Epoch 384/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6143\n",
            "Epoch 385/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6141\n",
            "Epoch 386/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6140\n",
            "Epoch 387/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6138\n",
            "Epoch 388/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6136\n",
            "Epoch 389/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6135\n",
            "Epoch 390/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6133\n",
            "Epoch 391/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6131\n",
            "Epoch 392/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6130\n",
            "Epoch 393/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.6128\n",
            "Epoch 394/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6127\n",
            "Epoch 395/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6125\n",
            "Epoch 396/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6123\n",
            "Epoch 397/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6122\n",
            "Epoch 398/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6120\n",
            "Epoch 399/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6119\n",
            "Epoch 400/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6117\n",
            "Epoch 401/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6116\n",
            "Epoch 402/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6114\n",
            "Epoch 403/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6112\n",
            "Epoch 404/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6110\n",
            "Epoch 405/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6109\n",
            "Epoch 406/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6107\n",
            "Epoch 407/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6106\n",
            "Epoch 408/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6104\n",
            "Epoch 409/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6102\n",
            "Epoch 410/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6101\n",
            "Epoch 411/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7500 - loss: 0.6099\n",
            "Epoch 412/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6098\n",
            "Epoch 413/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6096\n",
            "Epoch 414/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6095\n",
            "Epoch 415/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6093\n",
            "Epoch 416/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6091\n",
            "Epoch 417/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6090\n",
            "Epoch 418/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6089\n",
            "Epoch 419/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6087\n",
            "Epoch 420/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6085\n",
            "Epoch 421/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6083\n",
            "Epoch 422/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6082\n",
            "Epoch 423/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6080\n",
            "Epoch 424/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6078\n",
            "Epoch 425/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6077\n",
            "Epoch 426/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6076\n",
            "Epoch 427/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6074\n",
            "Epoch 428/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6072\n",
            "Epoch 429/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6070\n",
            "Epoch 430/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6069\n",
            "Epoch 431/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6068\n",
            "Epoch 432/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6066\n",
            "Epoch 433/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6064\n",
            "Epoch 434/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.6063\n",
            "Epoch 435/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6061\n",
            "Epoch 436/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6060\n",
            "Epoch 437/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6058\n",
            "Epoch 438/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6056\n",
            "Epoch 439/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6054\n",
            "Epoch 440/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.6053\n",
            "Epoch 441/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6052\n",
            "Epoch 442/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6050\n",
            "Epoch 443/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6048\n",
            "Epoch 444/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6047\n",
            "Epoch 445/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6045\n",
            "Epoch 446/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6044\n",
            "Epoch 447/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6042\n",
            "Epoch 448/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6040\n",
            "Epoch 449/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6038\n",
            "Epoch 450/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6037\n",
            "Epoch 451/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6036\n",
            "Epoch 452/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6034\n",
            "Epoch 453/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6032\n",
            "Epoch 454/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6030\n",
            "Epoch 455/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6029\n",
            "Epoch 456/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7500 - loss: 0.6027\n",
            "Epoch 457/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6026\n",
            "Epoch 458/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6024\n",
            "Epoch 459/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6023\n",
            "Epoch 460/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6021\n",
            "Epoch 461/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6019\n",
            "Epoch 462/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6017\n",
            "Epoch 463/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6016\n",
            "Epoch 464/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6014\n",
            "Epoch 465/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6013\n",
            "Epoch 466/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6011\n",
            "Epoch 467/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6010\n",
            "Epoch 468/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.6008\n",
            "Epoch 469/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6006\n",
            "Epoch 470/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6005\n",
            "Epoch 471/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6003\n",
            "Epoch 472/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6002\n",
            "Epoch 473/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6000\n",
            "Epoch 474/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.5998\n",
            "Epoch 475/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.5997\n",
            "Epoch 476/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5996\n",
            "Epoch 477/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5994\n",
            "Epoch 478/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5992\n",
            "Epoch 479/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.5991\n",
            "Epoch 480/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5989\n",
            "Epoch 481/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5987\n",
            "Epoch 482/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.5986\n",
            "Epoch 483/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.5984\n",
            "Epoch 484/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5982\n",
            "Epoch 485/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5981\n",
            "Epoch 486/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.5979\n",
            "Epoch 487/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.5978\n",
            "Epoch 488/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5976\n",
            "Epoch 489/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7500 - loss: 0.5975\n",
            "Epoch 490/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5973\n",
            "Epoch 491/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5971\n",
            "Epoch 492/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.5970\n",
            "Epoch 493/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5968\n",
            "Epoch 494/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5967\n",
            "Epoch 495/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5965\n",
            "Epoch 496/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5963\n",
            "Epoch 497/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5962\n",
            "Epoch 498/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.5961\n",
            "Epoch 499/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5959\n",
            "Epoch 500/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.5957\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7500 - loss: 0.5955\n",
            "Multi-Layer Perceptron Accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The training output shows that after 500 epochs, the Multi-Layer Perceptron (MLP) achieved an accuracy of 50% with a loss of 0.6954.\n",
        "- This means the model is only classifying correctly half of the time, which is equivalent to random guessing for a binary classification problem like XOR."
      ],
      "metadata": {
        "id": "34ekrPqV7wzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Visualization:**"
      ],
      "metadata": {
        "id": "tObXacaf6z8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the XOR data points\n",
        "plt.scatter(X[:,0], X[:,1], c=y, cmap='bwr', marker='o')\n",
        "\n",
        "# Define the grid range\n",
        "xx, yy = np.meshgrid(np.arange(-0.5, 1.5, 0.01), np.arange(-0.5, 1.5, 0.01))\n",
        "Z = mlp_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.contourf(xx, yy, Z, cmap='bwr', alpha=0.2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "5awV0_Jo63H6",
        "outputId": "93ad5d12-2f3b-482a-b623-4056648d0c8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interpretation:**\n",
        "\n",
        "1. The red and blue points represent two classes: XOR output 0 (blue) and XOR output 1 (red).\n",
        "2. The shaded regions show the model's decision boundary: blue for class 0 and red for class 1.\n",
        "3. The smooth gradient between blue and red indicates a non-linear decision boundary, needed for XOR classification.\n",
        "4. The model is correctly classifying the points, as the red points are in the red area and the blue points in the blue area.\n",
        "\n",
        "- This suggests the use of a multi-layer perceptron (MLP) to handle XOR's non-linear separability."
      ],
      "metadata": {
        "id": "CBHQ169I7Va4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation\n",
        "\n",
        "The MLP successfully classified some cases of the XOR problem, such as [0, 0] → 0 and [0, 1] → 1, but failed for others like [1, 0] and [1, 1], where the predictions were incorrect. This failure indicates that while the model has partially learned the XOR pattern, it struggles to generalize to all cases. The primary reason for this is likely the XOR function's non-linear separability, which requires a more complex model architecture. The hidden layer may not have enough neurons to capture the non-linearity"
      ],
      "metadata": {
        "id": "uDuA_N-2I2yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9r0-iypI_yz",
        "outputId": "8fcb3bef-34f3-47db-b9a6-d07f3e0787a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C3LgcdtLI5Zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2:**\n",
        "\n",
        "## A. Sentiment Analysis Twitter Airline"
      ],
      "metadata": {
        "id": "bXFElhZZ7-4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading and Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "cVfkTl93_F6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Importing the necessary libraries**"
      ],
      "metadata": {
        "id": "QLHEj0Ui8x8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import History\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "z6EdtUXG8yUi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Loading the Dataset**"
      ],
      "metadata": {
        "id": "nTmKJMW-9c84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/neural network/Tweets - Tweets.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "vZZd3AZY9fwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d44ec99-ff6c-403d-e495-478903b97fd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
            "0  5.703061e+17           neutral                        1.0000   \n",
            "1  5.703011e+17          positive                        0.3486   \n",
            "2  5.703011e+17           neutral                        0.6837   \n",
            "3  5.703010e+17          negative                        1.0000   \n",
            "4  5.703008e+17          negative                        1.0000   \n",
            "\n",
            "  negativereason  negativereason_confidence         airline  \\\n",
            "0            NaN                        NaN  Virgin America   \n",
            "1            NaN                     0.0000  Virgin America   \n",
            "2            NaN                        NaN  Virgin America   \n",
            "3     Bad Flight                     0.7033  Virgin America   \n",
            "4     Can't Tell                     1.0000  Virgin America   \n",
            "\n",
            "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
            "0                    NaN     cairdin                 NaN              0   \n",
            "1                    NaN    jnardino                 NaN              0   \n",
            "2                    NaN  yvonnalynn                 NaN              0   \n",
            "3                    NaN    jnardino                 NaN              0   \n",
            "4                    NaN    jnardino                 NaN              0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0                @VirginAmerica What @dhepburn said.         NaN   \n",
            "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
            "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
            "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
            "\n",
            "               tweet_created tweet_location               user_timezone  \n",
            "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
            "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
            "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
            "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
            "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Pre-processing the data**"
      ],
      "metadata": {
        "id": "GiuIC4C69mpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns (text and sentiment)\n",
        "data = data[['text', 'airline_sentiment']]\n",
        "\n",
        "# Convert sentiment to binary classification: Positive = 1, Negative = 0\n",
        "data['airline_sentiment'] = data['airline_sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "# Tokenization and padding\n",
        "max_words = 5000  # Maximum number of words to use\n",
        "max_len = 100  # Maximum length of each sequence\n",
        "\n",
        "# Tokenizer for text data\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data['text'])\n",
        "sequences = tokenizer.texts_to_sequences(data['text'])\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Labels\n",
        "y = data['airline_sentiment'].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "id": "K7J5opeQ905_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456acc81-6d5c-4461-d413-944d15037358"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-32a1d55bdc87>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['airline_sentiment'] = data['airline_sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (11712, 100)\n",
            "Testing data shape: (2928, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Creating a Simple Feed-Forward Neural Network"
      ],
      "metadata": {
        "id": "lMs_W55w_Da0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(activation_function='relu'):\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer and first hidden layer\n",
        "    model.add(Dense(128, input_shape=(max_len,), activation=activation_function))\n",
        "\n",
        "    # Second hidden layer\n",
        "    model.add(Dense(64, activation=activation_function))\n",
        "\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with Adam optimizer and binary crossentropy loss\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3Hksl8H0-Y-z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A simple feed-forward neural network is created using the build_model function.\n",
        "- It includes an input layer, two hidden layers, and an output layer configured for binary classification."
      ],
      "metadata": {
        "id": "p8R0js75BasJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training the Model Using Backpropagation"
      ],
      "metadata": {
        "id": "oWWGie-n_W3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Assuming max_len is defined somewhere in your code, replace with actual value if needed\n",
        "max_len = 100\n",
        "\n",
        "def build_model(activation_function='relu'):\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer and first hidden layer\n",
        "    model.add(Dense(128, input_shape=(max_len,), activation=activation_function))\n",
        "\n",
        "    # Second hidden layer\n",
        "    model.add(Dense(64, activation=activation_function))\n",
        "\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with Adam optimizer and binary crossentropy loss\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model instance\n",
        "model = build_model() # Call the function to build and compile the model\n",
        "\n",
        "\n",
        "# Train the model using backpropagation\n",
        "#The following line is no longer needed since the model is already compiled within build_model\n",
        "#model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "#              loss='binary_crossentropy',\n",
        "#              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJoUv0k_Wm-",
        "outputId": "073efaf3-d9d6-444e-cb63-f3cb146bfd98"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 23.9519 - val_accuracy: 0.7824 - val_loss: 5.2076\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7606 - loss: 4.3148 - val_accuracy: 0.7510 - val_loss: 3.4410\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7569 - loss: 2.9671 - val_accuracy: 0.7466 - val_loss: 2.7290\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7619 - loss: 2.0124 - val_accuracy: 0.7514 - val_loss: 2.2133\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 1.5101 - val_accuracy: 0.7015 - val_loss: 1.7836\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7836 - loss: 1.1803 - val_accuracy: 0.7831 - val_loss: 1.5111\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 1.1018 - val_accuracy: 0.8190 - val_loss: 1.4384\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.8779 - val_accuracy: 0.8296 - val_loss: 1.3970\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.7173 - val_accuracy: 0.7951 - val_loss: 1.0184\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8066 - loss: 0.6948 - val_accuracy: 0.8012 - val_loss: 0.9865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The model is compiled with the Adam optimizer and binary cross-entropy loss function, which allows for backpropagation to update weights based on the loss calculated during training.\n",
        "- Training: The fit method runs the training process, which applies backpropagation to update the weights iteratively."
      ],
      "metadata": {
        "id": "qFDaFKrGB7vK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Experimenting with Different Activation Functions"
      ],
      "metadata": {
        "id": "srU1q5gr_gk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different activation functions\n",
        "activation_functions = ['sigmoid', 'relu', 'tanh']\n",
        "histories = {}\n",
        "\n",
        "for activation in activation_functions:\n",
        "    print(f\"\\nTraining with {activation} activation function\\n\")\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model(activation_function=activation)\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=10,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Store the training history for comparison\n",
        "    histories[activation] = history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQfm5VCp_hg9",
        "outputId": "53b0e846-9078-4ba2-8341-8114806a2a78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with sigmoid activation function\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4542 - val_accuracy: 0.8432 - val_loss: 0.4107\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4297 - val_accuracy: 0.8381 - val_loss: 0.4242\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4298 - val_accuracy: 0.8436 - val_loss: 0.4067\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.4198 - val_accuracy: 0.8443 - val_loss: 0.4078\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.4151 - val_accuracy: 0.8446 - val_loss: 0.4042\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4269 - val_accuracy: 0.8426 - val_loss: 0.4066\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8389 - loss: 0.4169 - val_accuracy: 0.8432 - val_loss: 0.4115\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8414 - loss: 0.4115 - val_accuracy: 0.8408 - val_loss: 0.4083\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.4167 - val_accuracy: 0.8439 - val_loss: 0.4075\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.4193 - val_accuracy: 0.8429 - val_loss: 0.4070\n",
            "\n",
            "Training with relu activation function\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 13.6447 - val_accuracy: 0.8227 - val_loss: 5.5158\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7491 - loss: 4.0313 - val_accuracy: 0.7565 - val_loss: 2.7941\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7668 - loss: 2.1822 - val_accuracy: 0.7606 - val_loss: 2.1489\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7659 - loss: 1.4362 - val_accuracy: 0.7462 - val_loss: 1.7794\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.9830 - val_accuracy: 0.6100 - val_loss: 1.5358\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.8049 - val_accuracy: 0.8224 - val_loss: 1.0048\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.6731 - val_accuracy: 0.7879 - val_loss: 0.8472\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8062 - loss: 0.5581 - val_accuracy: 0.7640 - val_loss: 0.7647\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4818 - val_accuracy: 0.8060 - val_loss: 0.7102\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4580 - val_accuracy: 0.8029 - val_loss: 0.6434\n",
            "\n",
            "Training with tanh activation function\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.4591 - val_accuracy: 0.8429 - val_loss: 0.4169\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.4344 - val_accuracy: 0.8429 - val_loss: 0.4128\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.4219 - val_accuracy: 0.8395 - val_loss: 0.4136\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4118 - val_accuracy: 0.8443 - val_loss: 0.4134\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8395 - loss: 0.4130 - val_accuracy: 0.8436 - val_loss: 0.4099\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8421 - loss: 0.4075 - val_accuracy: 0.8432 - val_loss: 0.4090\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8414 - loss: 0.4071 - val_accuracy: 0.8460 - val_loss: 0.4091\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.4102 - val_accuracy: 0.8460 - val_loss: 0.4073\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.4101 - val_accuracy: 0.8432 - val_loss: 0.4117\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.4085 - val_accuracy: 0.8408 - val_loss: 0.4181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluating the Model and Plotting Loss over Epochs"
      ],
      "metadata": {
        "id": "2Q5NhDvs_moa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss for each activation function\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for activation in activation_functions:\n",
        "    plt.plot(histories[activation].history['loss'], label=f'{activation} Loss')\n",
        "\n",
        "plt.title('Loss Over Epochs for Different Activation Functions')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "for activation in activation_functions:\n",
        "    print(f\"\\nEvaluating model with {activation} activation function:\")\n",
        "    model = build_model(activation_function=activation)\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)  # Retrain\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "OXwWvZEj_r4N",
        "outputId": "e33b7cd4-576d-4659-e83e-f0ebd555b129"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model with sigmoid activation function:\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8358 - loss: 0.4217\n",
            "Test Accuracy: 84.26%\n",
            "\n",
            "Evaluating model with relu activation function:\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.9359\n",
            "Test Accuracy: 81.39%\n",
            "\n",
            "Evaluating model with tanh activation function:\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.4272\n",
            "Test Accuracy: 84.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment Analysis Model Evaluation:**\n",
        "\n",
        "**1. Sigmoid Activation Function:**\n",
        "\n",
        "- Accuracy: 84.22%\n",
        "- Interpretation:\n",
        "The model successfully classified approximately 84.22% of the tweets as either positive or negative, indicating strong performance in identifying sentiments in the text. The low loss value (0.4211) suggests the model's predictions were quite accurate.\n",
        "\n",
        "**2. ReLU Activation Function:**\n",
        "\n",
        "- Accuracy: 77.73%\n",
        "- Interpretation:\n",
        "The ReLU model performed the weakest among the three, accurately classifying only 78% of sentiments. The higher loss (1.0381) indicates that this model struggled more with making correct predictions compared to the others.\n",
        "\n",
        "**3. Tanh Activation Function:**\n",
        "\n",
        "- Accuracy: 84.15%\n",
        "- Interpretation:\n",
        "The tanh model slightly outperformed the sigmoid model, achieving an accuracy of 84.15%. This indicates effective sentiment classification, with a comparable loss (0.4224), suggesting accurate predictions."
      ],
      "metadata": {
        "id": "VAzP4izcAiyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary:**\n",
        "\n",
        "- The sigmoid activation function proved to be the most effective for sentiment analysis in this context, closely followed by the tanh function. Both models demonstrated the ability to classify sentiments accurately.\n",
        "- In contrast, the ReLU function showed lower performance, highlighting its potential inadequacy for this type of text classification task.\n"
      ],
      "metadata": {
        "id": "F8mbx82WAzy_"
      }
    }
  ]
}